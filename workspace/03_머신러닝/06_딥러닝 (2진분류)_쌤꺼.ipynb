{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb944ade",
   "metadata": {},
   "source": [
    "### 딥러닝 알고리즘\n",
    "- tensorflow + keras \n",
    "- tensorflow : 딥러닝을 수행할 수 있는 라이브러리\n",
    "- keras : tensorflow 프로그래밍을 쉽게 할 수 있도록 만든 라이브러리.\n",
    "- pytorch + pytorch lightning\n",
    "- pytorch : 딥러닝을 수행할 수 있는 라이브러리\n",
    "- pytorch lightning : pytorch 프로그래밍을 쉽게 할 수 있도록 만든 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d26f67",
   "metadata": {},
   "source": [
    "### tensorflow 설치\n",
    "- anaconda prompt 에서 pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028d7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 불필요한 경고가 뜨지 않게..\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터 전처리 알고리즘 (비지도 학습)\n",
    "# 문자열 데이터를 숫자로 변환한다.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 표준편차를 기반으로 표준화 한다.\n",
    "# 잘못된 학습을 정상화 시키는 목적으로 사용한다.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터를 학습용과 검증으로 나눈다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 교차 검증\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 평가 함수\n",
    "# 정확도 평가 함수\n",
    "from sklearn.metrics import accuracy_score\n",
    "# mse 평가 함수\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 학습 알고리즘 - 분류\n",
    "# 최 근접 이웃\n",
    "# 학습시 : 주어진 데이터를 저장만 한다.\n",
    "# 예측 : 주변의 데이터를 보고 가장 많은 결과로 결정한다.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 선형\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# 트리\n",
    "# 학습시 : 주어진 데이터를 가지고 질문들을 생성한다.\n",
    "# 예측시 : 질문을 통해 최종 결과를 예측한다.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# 앙상블 - 다수의 알고리즘이 던지는 결과를 취합하여 최종 결과를 결정한다.\n",
    "# 트리들을 사용한다.\n",
    "# 학습시 - 데이터를 랜덤하게 섞어서 80%를 추출한다.\n",
    "# 이렇게 추출된 데이터를 트리의 개수만큼 생성하여 각 트리들에게 주고\n",
    "# 학습을 수행한다.\n",
    "# 예측시 - 각 트리가 던지는 결과를 취합하여 다수결의 원칙으로 최종 결과를\n",
    "# 결정한다.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 부스팅\n",
    "# 앙상블 알고리즘이 잘못 예측한 데이터를 다시 학습하는 방식\n",
    "# 학습과 예측 원리를 앙상블과 동일하다.\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 학습 알고리즘 - 회귀\n",
    "# 최 근접 이웃\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# 선형\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "# 트리\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# 앙상블\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 부스팅\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# 딥러닝\n",
    "import tensorflow as tf\n",
    "\n",
    "# 딥러닝 모델의 각 층을 관리하는 객체\n",
    "from tensorflow.keras.models import Sequential\n",
    "# 선형회귀를 수행하는 은닉층\n",
    "from tensorflow.keras.layers import Dense\n",
    "# 활성화 함수를 관리하는 것\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# 조기중단\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 성능이 개선되면 모델을 파일로 자동 저장한다\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 저장된 딥러닝모델 불러오기 .h5파일\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa24e01",
   "metadata": {},
   "source": [
    "### 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e5d143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>21.10</td>\n",
       "      <td>20.52</td>\n",
       "      <td>138.10</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>0.09684</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.15720</td>\n",
       "      <td>0.11550</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>...</td>\n",
       "      <td>32.07</td>\n",
       "      <td>168.20</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0.13680</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.22800</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.07425</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>11.87</td>\n",
       "      <td>21.54</td>\n",
       "      <td>76.83</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08777</td>\n",
       "      <td>0.02386</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.06612</td>\n",
       "      <td>...</td>\n",
       "      <td>28.18</td>\n",
       "      <td>83.51</td>\n",
       "      <td>507.2</td>\n",
       "      <td>0.09457</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>0.2305</td>\n",
       "      <td>0.09952</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>19.59</td>\n",
       "      <td>25.00</td>\n",
       "      <td>127.70</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>0.10320</td>\n",
       "      <td>0.09871</td>\n",
       "      <td>0.16550</td>\n",
       "      <td>0.09063</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.05391</td>\n",
       "      <td>...</td>\n",
       "      <td>30.96</td>\n",
       "      <td>139.80</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>0.15280</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.06091</td>\n",
       "      <td>malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>12.00</td>\n",
       "      <td>28.23</td>\n",
       "      <td>76.77</td>\n",
       "      <td>442.5</td>\n",
       "      <td>0.08437</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>0.04055</td>\n",
       "      <td>0.01945</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.06104</td>\n",
       "      <td>...</td>\n",
       "      <td>37.88</td>\n",
       "      <td>85.07</td>\n",
       "      <td>523.7</td>\n",
       "      <td>0.12080</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.07116</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.08194</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.13470</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "449        21.10         20.52          138.10     1384.0          0.09684   \n",
       "450        11.87         21.54           76.83      432.0          0.06613   \n",
       "451        19.59         25.00          127.70     1191.0          0.10320   \n",
       "452        12.00         28.23           76.77      442.5          0.08437   \n",
       "453        14.53         13.98           93.86      644.2          0.10990   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "449           0.11750         0.15720              0.11550         0.1554   \n",
       "450           0.10640         0.08777              0.02386         0.1349   \n",
       "451           0.09871         0.16550              0.09063         0.1663   \n",
       "452           0.06450         0.04055              0.01945         0.1615   \n",
       "453           0.09242         0.06895              0.06495         0.1650   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "449                 0.05661  ...          32.07           168.20      2022.0   \n",
       "450                 0.06612  ...          28.18            83.51       507.2   \n",
       "451                 0.05391  ...          30.96           139.80      1421.0   \n",
       "452                 0.06104  ...          37.88            85.07       523.7   \n",
       "453                 0.06121  ...          16.93           103.10       749.9   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220             0.6656           0.7119   \n",
       "1             0.12380             0.1866           0.2416   \n",
       "2             0.14440             0.4245           0.4504   \n",
       "3             0.20980             0.8663           0.6869   \n",
       "4             0.13740             0.2050           0.4000   \n",
       "..                ...                ...              ...   \n",
       "449           0.13680             0.3101           0.4399   \n",
       "450           0.09457             0.3399           0.3218   \n",
       "451           0.15280             0.1845           0.3977   \n",
       "452           0.12080             0.1856           0.1811   \n",
       "453           0.13470             0.1478           0.1373   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension     target  \n",
       "0                 0.26540          0.4601                  0.11890  malignant  \n",
       "1                 0.18600          0.2750                  0.08902  malignant  \n",
       "2                 0.24300          0.3613                  0.08758  malignant  \n",
       "3                 0.25750          0.6638                  0.17300  malignant  \n",
       "4                 0.16250          0.2364                  0.07678  malignant  \n",
       "..                    ...             ...                      ...        ...  \n",
       "449               0.22800          0.2268                  0.07425  malignant  \n",
       "450               0.08750          0.2305                  0.09952     benign  \n",
       "451               0.14660          0.2293                  0.06091  malignant  \n",
       "452               0.07116          0.2447                  0.08194     benign  \n",
       "453               0.10690          0.2606                  0.07810     benign  \n",
       "\n",
       "[454 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/breast_cancer.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb94e9",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533183fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>21.10</td>\n",
       "      <td>20.52</td>\n",
       "      <td>138.10</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>0.09684</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.15720</td>\n",
       "      <td>0.11550</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>...</td>\n",
       "      <td>25.68</td>\n",
       "      <td>32.07</td>\n",
       "      <td>168.20</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0.13680</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.22800</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.07425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>11.87</td>\n",
       "      <td>21.54</td>\n",
       "      <td>76.83</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0.06613</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.08777</td>\n",
       "      <td>0.02386</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.06612</td>\n",
       "      <td>...</td>\n",
       "      <td>12.79</td>\n",
       "      <td>28.18</td>\n",
       "      <td>83.51</td>\n",
       "      <td>507.2</td>\n",
       "      <td>0.09457</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>0.2305</td>\n",
       "      <td>0.09952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>19.59</td>\n",
       "      <td>25.00</td>\n",
       "      <td>127.70</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>0.10320</td>\n",
       "      <td>0.09871</td>\n",
       "      <td>0.16550</td>\n",
       "      <td>0.09063</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.05391</td>\n",
       "      <td>...</td>\n",
       "      <td>21.44</td>\n",
       "      <td>30.96</td>\n",
       "      <td>139.80</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>0.15280</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.06091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>12.00</td>\n",
       "      <td>28.23</td>\n",
       "      <td>76.77</td>\n",
       "      <td>442.5</td>\n",
       "      <td>0.08437</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>0.04055</td>\n",
       "      <td>0.01945</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.06104</td>\n",
       "      <td>...</td>\n",
       "      <td>13.09</td>\n",
       "      <td>37.88</td>\n",
       "      <td>85.07</td>\n",
       "      <td>523.7</td>\n",
       "      <td>0.12080</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.07116</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>0.08194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.13470</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "449        21.10         20.52          138.10     1384.0          0.09684   \n",
       "450        11.87         21.54           76.83      432.0          0.06613   \n",
       "451        19.59         25.00          127.70     1191.0          0.10320   \n",
       "452        12.00         28.23           76.77      442.5          0.08437   \n",
       "453        14.53         13.98           93.86      644.2          0.10990   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "449           0.11750         0.15720              0.11550         0.1554   \n",
       "450           0.10640         0.08777              0.02386         0.1349   \n",
       "451           0.09871         0.16550              0.09063         0.1663   \n",
       "452           0.06450         0.04055              0.01945         0.1615   \n",
       "453           0.09242         0.06895              0.06495         0.1650   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...         25.38          17.33   \n",
       "1                   0.05667  ...         24.99          23.41   \n",
       "2                   0.05999  ...         23.57          25.53   \n",
       "3                   0.09744  ...         14.91          26.50   \n",
       "4                   0.05883  ...         22.54          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "449                 0.05661  ...         25.68          32.07   \n",
       "450                 0.06612  ...         12.79          28.18   \n",
       "451                 0.05391  ...         21.44          30.96   \n",
       "452                 0.06104  ...         13.09          37.88   \n",
       "453                 0.06121  ...         15.80          16.93   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220             0.6656   \n",
       "1             158.80      1956.0           0.12380             0.1866   \n",
       "2             152.50      1709.0           0.14440             0.4245   \n",
       "3              98.87       567.7           0.20980             0.8663   \n",
       "4             152.20      1575.0           0.13740             0.2050   \n",
       "..               ...         ...               ...                ...   \n",
       "449           168.20      2022.0           0.13680             0.3101   \n",
       "450            83.51       507.2           0.09457             0.3399   \n",
       "451           139.80      1421.0           0.15280             0.1845   \n",
       "452            85.07       523.7           0.12080             0.1856   \n",
       "453           103.10       749.9           0.13470             0.1478   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119               0.26540          0.4601   \n",
       "1             0.2416               0.18600          0.2750   \n",
       "2             0.4504               0.24300          0.3613   \n",
       "3             0.6869               0.25750          0.6638   \n",
       "4             0.4000               0.16250          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "449           0.4399               0.22800          0.2268   \n",
       "450           0.3218               0.08750          0.2305   \n",
       "451           0.3977               0.14660          0.2293   \n",
       "452           0.1811               0.07116          0.2447   \n",
       "453           0.1373               0.10690          0.2606   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "449                  0.07425  \n",
       "450                  0.09952  \n",
       "451                  0.06091  \n",
       "452                  0.08194  \n",
       "453                  0.07810  \n",
       "\n",
       "[454 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      malignant\n",
       "1      malignant\n",
       "2      malignant\n",
       "3      malignant\n",
       "4      malignant\n",
       "         ...    \n",
       "449    malignant\n",
       "450       benign\n",
       "451    malignant\n",
       "452       benign\n",
       "453       benign\n",
       "Name: target, Length: 454, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 입력과 결과로 나눈다.\n",
    "X = df1.drop('target', axis=1)\n",
    "y = df1['target']\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1351a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력데이터 X 의 컬럼 개수를 파악한다.\n",
    "n_features = X.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7432c232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 데이터의 종류 수\n",
    "a1 = y.value_counts()\n",
    "n_classes = len(a1)\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1026672e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자 -> 숫자\n",
    "encoder1 = LabelEncoder()\n",
    "y = encoder1.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338d6642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0716471 , -2.11021126,  1.24691885, ...,  2.21627442,\n",
       "         2.57629265,  1.89296305],\n",
       "       [ 1.80872514, -0.29975355,  1.665741  , ...,  1.02843583,\n",
       "        -0.29491256,  0.27048275],\n",
       "       [ 1.55731868,  0.55280299,  1.54548514, ...,  1.88116631,\n",
       "         1.04374227,  0.19229093],\n",
       "       ...,\n",
       "       [ 1.52874976,  1.47150615,  1.4501098 , ...,  0.43900458,\n",
       "        -1.00379467, -1.25588676],\n",
       "       [-0.63963097,  2.26281581, -0.66183197, ..., -0.68959168,\n",
       "        -0.76491536, -0.11396037],\n",
       "       [ 0.0831626 , -1.22825622,  0.04684827, ..., -0.15491471,\n",
       "        -0.51828023, -0.32247189]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표준화\n",
    "# 머신러닝 -> 학습이 정상적으로 이루어지기 위해...\n",
    "# 딥러닝 -> 학습 속도를 빠르게 하기 위해..\n",
    "scaler1 = StandardScaler()\n",
    "X = scaler1.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "761b13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤을 고정한다.\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce017fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 설계한다.\n",
    "model = Sequential()\n",
    "\n",
    "# 첫 번째 인닉층은 input_dim 속성을 통해 입력층의 노드를 설정해 준다.\n",
    "model.add(Dense(40, input_dim=n_features))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 출력층\n",
    "# 2진 분류의 경우\n",
    "# 출력층의 노드의 개수는 1개\n",
    "# 출력층의 활성화 함수는 sigmoid\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d2bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "# loss : 오차를 평가할 함수. \n",
    "# 2진 분류 : binary_crossentropy\n",
    "# optimizer : 경사하강법. adam을 사용한다.\n",
    "# metircs : 학습 중 평가를 위한 함수. accuracy\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80444ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용과 검증용 데이터로 나눈다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de660b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조기 중단\n",
    "# 검증용 데이터의 손실률을 모니터링 하면서 더이상 개선되지 않는 다고 한다면\n",
    "# 학습을 중단시킨다.\n",
    "# patience : 손실률을 몇번을 더 볼것인가를 설정한다. 손실률이 개선되고 여기서\n",
    "# 정한 학습 횟수만큼 더 진행이 되는 동안에 개선이되지 않는다면 중단한다.\n",
    "callback1 = EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15dcf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동저장\n",
    "# 검증용 데이터의 손실률을 모니터링 하게 하여 개선이 될 경우 저장한다\n",
    "file_name = '06_model.h5'\n",
    "\n",
    "# save_best_only : 모니터링하는 순실률의 최하 수치보다 더 개선될때만 저장\n",
    "# True안넣으면 patience 50번 더 갔을 때 모델로 저장됨\n",
    "callback2 = ModelCheckpoint(filepath=file_name, monitor = 'val_loss', save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628966e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7388 - accuracy: 0.5765 - val_loss: 0.6556 - val_accuracy: 0.6316\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7081 - accuracy: 0.5765 - val_loss: 0.6297 - val_accuracy: 0.6404\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6792 - accuracy: 0.5824 - val_loss: 0.6052 - val_accuracy: 0.6491\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6521 - accuracy: 0.5853 - val_loss: 0.5826 - val_accuracy: 0.6579\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6266 - accuracy: 0.6000 - val_loss: 0.5620 - val_accuracy: 0.6754\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6027 - accuracy: 0.6176 - val_loss: 0.5425 - val_accuracy: 0.6842\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5800 - accuracy: 0.6441 - val_loss: 0.5239 - val_accuracy: 0.6842\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.5585 - accuracy: 0.6559 - val_loss: 0.5061 - val_accuracy: 0.7193\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.5382 - accuracy: 0.6706 - val_loss: 0.4889 - val_accuracy: 0.7368\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5189 - accuracy: 0.7118 - val_loss: 0.4726 - val_accuracy: 0.7719\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.5007 - accuracy: 0.7471 - val_loss: 0.4569 - val_accuracy: 0.7982\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4835 - accuracy: 0.7882 - val_loss: 0.4423 - val_accuracy: 0.8158\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4672 - accuracy: 0.8059 - val_loss: 0.4283 - val_accuracy: 0.8333\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4517 - accuracy: 0.8265 - val_loss: 0.4150 - val_accuracy: 0.8509\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4370 - accuracy: 0.8382 - val_loss: 0.4024 - val_accuracy: 0.8772\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.4229 - accuracy: 0.8529 - val_loss: 0.3904 - val_accuracy: 0.8772\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4095 - accuracy: 0.8618 - val_loss: 0.3790 - val_accuracy: 0.8772\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3968 - accuracy: 0.8794 - val_loss: 0.3684 - val_accuracy: 0.8947\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3846 - accuracy: 0.8912 - val_loss: 0.3581 - val_accuracy: 0.9035\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3730 - accuracy: 0.9000 - val_loss: 0.3481 - val_accuracy: 0.9035\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3620 - accuracy: 0.9059 - val_loss: 0.3388 - val_accuracy: 0.9035\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3515 - accuracy: 0.9088 - val_loss: 0.3298 - val_accuracy: 0.9035\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3415 - accuracy: 0.9147 - val_loss: 0.3211 - val_accuracy: 0.9298\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3319 - accuracy: 0.9176 - val_loss: 0.3128 - val_accuracy: 0.9298\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3226 - accuracy: 0.9235 - val_loss: 0.3048 - val_accuracy: 0.9298\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.3137 - accuracy: 0.9265 - val_loss: 0.2971 - val_accuracy: 0.9298\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3050 - accuracy: 0.9294 - val_loss: 0.2898 - val_accuracy: 0.9211\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2965 - accuracy: 0.9353 - val_loss: 0.2828 - val_accuracy: 0.9211\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2884 - accuracy: 0.9382 - val_loss: 0.2759 - val_accuracy: 0.9211\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2805 - accuracy: 0.9412 - val_loss: 0.2692 - val_accuracy: 0.9298\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2730 - accuracy: 0.9412 - val_loss: 0.2629 - val_accuracy: 0.9298\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2656 - accuracy: 0.9412 - val_loss: 0.2567 - val_accuracy: 0.9211\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2586 - accuracy: 0.9441 - val_loss: 0.2508 - val_accuracy: 0.9211\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2517 - accuracy: 0.9441 - val_loss: 0.2451 - val_accuracy: 0.9298\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2450 - accuracy: 0.9441 - val_loss: 0.2396 - val_accuracy: 0.9298\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2385 - accuracy: 0.9441 - val_loss: 0.2343 - val_accuracy: 0.9298\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2322 - accuracy: 0.9441 - val_loss: 0.2291 - val_accuracy: 0.9298\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2261 - accuracy: 0.9441 - val_loss: 0.2240 - val_accuracy: 0.9298\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2201 - accuracy: 0.9471 - val_loss: 0.2191 - val_accuracy: 0.9298\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2143 - accuracy: 0.9500 - val_loss: 0.2143 - val_accuracy: 0.9298\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2087 - accuracy: 0.9529 - val_loss: 0.2096 - val_accuracy: 0.9298\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2033 - accuracy: 0.9529 - val_loss: 0.2049 - val_accuracy: 0.9298\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1979 - accuracy: 0.9559 - val_loss: 0.2005 - val_accuracy: 0.9298\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1927 - accuracy: 0.9588 - val_loss: 0.1962 - val_accuracy: 0.9298\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1877 - accuracy: 0.9588 - val_loss: 0.1920 - val_accuracy: 0.9298\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1827 - accuracy: 0.9588 - val_loss: 0.1880 - val_accuracy: 0.9298\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1780 - accuracy: 0.9618 - val_loss: 0.1840 - val_accuracy: 0.9298\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1734 - accuracy: 0.9618 - val_loss: 0.1803 - val_accuracy: 0.9474\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1689 - accuracy: 0.9647 - val_loss: 0.1767 - val_accuracy: 0.9474\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1645 - accuracy: 0.9647 - val_loss: 0.1733 - val_accuracy: 0.9474\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1603 - accuracy: 0.9676 - val_loss: 0.1701 - val_accuracy: 0.9474\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1562 - accuracy: 0.9706 - val_loss: 0.1669 - val_accuracy: 0.9561\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1522 - accuracy: 0.9735 - val_loss: 0.1639 - val_accuracy: 0.9561\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1483 - accuracy: 0.9735 - val_loss: 0.1611 - val_accuracy: 0.9561\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1445 - accuracy: 0.9735 - val_loss: 0.1584 - val_accuracy: 0.9561\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1409 - accuracy: 0.9794 - val_loss: 0.1558 - val_accuracy: 0.9649\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1373 - accuracy: 0.9794 - val_loss: 0.1533 - val_accuracy: 0.9649\n",
      "Epoch 58/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1339 - accuracy: 0.9794 - val_loss: 0.1510 - val_accuracy: 0.9649\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1306 - accuracy: 0.9824 - val_loss: 0.1487 - val_accuracy: 0.9649\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1274 - accuracy: 0.9824 - val_loss: 0.1466 - val_accuracy: 0.9649\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1243 - accuracy: 0.9824 - val_loss: 0.1445 - val_accuracy: 0.9649\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1213 - accuracy: 0.9824 - val_loss: 0.1424 - val_accuracy: 0.9649\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1184 - accuracy: 0.9853 - val_loss: 0.1404 - val_accuracy: 0.9649\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1156 - accuracy: 0.9853 - val_loss: 0.1385 - val_accuracy: 0.9561\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1129 - accuracy: 0.9882 - val_loss: 0.1368 - val_accuracy: 0.9561\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1103 - accuracy: 0.9882 - val_loss: 0.1351 - val_accuracy: 0.9561\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1078 - accuracy: 0.9882 - val_loss: 0.1334 - val_accuracy: 0.9561\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1053 - accuracy: 0.9882 - val_loss: 0.1319 - val_accuracy: 0.9561\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1029 - accuracy: 0.9882 - val_loss: 0.1305 - val_accuracy: 0.9561\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1006 - accuracy: 0.9882 - val_loss: 0.1291 - val_accuracy: 0.9561\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0984 - accuracy: 0.9882 - val_loss: 0.1279 - val_accuracy: 0.9561\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0962 - accuracy: 0.9882 - val_loss: 0.1268 - val_accuracy: 0.9561\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0941 - accuracy: 0.9882 - val_loss: 0.1257 - val_accuracy: 0.9561\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0921 - accuracy: 0.9882 - val_loss: 0.1246 - val_accuracy: 0.9561\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0901 - accuracy: 0.9882 - val_loss: 0.1235 - val_accuracy: 0.9561\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0882 - accuracy: 0.9912 - val_loss: 0.1226 - val_accuracy: 0.9561\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0864 - accuracy: 0.9912 - val_loss: 0.1216 - val_accuracy: 0.9561\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0846 - accuracy: 0.9912 - val_loss: 0.1208 - val_accuracy: 0.9561\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0828 - accuracy: 0.9912 - val_loss: 0.1200 - val_accuracy: 0.9561\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0812 - accuracy: 0.9912 - val_loss: 0.1192 - val_accuracy: 0.9561\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0795 - accuracy: 0.9912 - val_loss: 0.1184 - val_accuracy: 0.9561\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0779 - accuracy: 0.9941 - val_loss: 0.1177 - val_accuracy: 0.9561\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0764 - accuracy: 0.9941 - val_loss: 0.1170 - val_accuracy: 0.9561\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0749 - accuracy: 0.9941 - val_loss: 0.1164 - val_accuracy: 0.9561\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0735 - accuracy: 0.9941 - val_loss: 0.1159 - val_accuracy: 0.9561\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0721 - accuracy: 0.9941 - val_loss: 0.1154 - val_accuracy: 0.9561\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0707 - accuracy: 0.9941 - val_loss: 0.1149 - val_accuracy: 0.9561\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0694 - accuracy: 0.9941 - val_loss: 0.1144 - val_accuracy: 0.9561\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0681 - accuracy: 0.9941 - val_loss: 0.1140 - val_accuracy: 0.9561\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0668 - accuracy: 0.9941 - val_loss: 0.1137 - val_accuracy: 0.9561\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0656 - accuracy: 0.9941 - val_loss: 0.1133 - val_accuracy: 0.9561\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0644 - accuracy: 0.9941 - val_loss: 0.1130 - val_accuracy: 0.9561\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0632 - accuracy: 0.9941 - val_loss: 0.1127 - val_accuracy: 0.9561\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0621 - accuracy: 0.9941 - val_loss: 0.1124 - val_accuracy: 0.9561\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0610 - accuracy: 0.9941 - val_loss: 0.1122 - val_accuracy: 0.9561\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0599 - accuracy: 0.9941 - val_loss: 0.1119 - val_accuracy: 0.9561\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0589 - accuracy: 0.9941 - val_loss: 0.1117 - val_accuracy: 0.9561\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0579 - accuracy: 0.9941 - val_loss: 0.1115 - val_accuracy: 0.9561\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0569 - accuracy: 0.9941 - val_loss: 0.1114 - val_accuracy: 0.9561\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0559 - accuracy: 0.9941 - val_loss: 0.1112 - val_accuracy: 0.9561\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0550 - accuracy: 0.9941 - val_loss: 0.1110 - val_accuracy: 0.9561\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0540 - accuracy: 0.9941 - val_loss: 0.1109 - val_accuracy: 0.9561\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0531 - accuracy: 0.9941 - val_loss: 0.1107 - val_accuracy: 0.9561\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0522 - accuracy: 0.9941 - val_loss: 0.1106 - val_accuracy: 0.9561\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0513 - accuracy: 0.9941 - val_loss: 0.1105 - val_accuracy: 0.9561\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0504 - accuracy: 0.9941 - val_loss: 0.1105 - val_accuracy: 0.9561\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0496 - accuracy: 0.9941 - val_loss: 0.1104 - val_accuracy: 0.9561\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0488 - accuracy: 0.9941 - val_loss: 0.1104 - val_accuracy: 0.9561\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0480 - accuracy: 0.9941 - val_loss: 0.1103 - val_accuracy: 0.9561\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0472 - accuracy: 0.9941 - val_loss: 0.1103 - val_accuracy: 0.9561\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0464 - accuracy: 0.9941 - val_loss: 0.1103 - val_accuracy: 0.9561\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0456 - accuracy: 0.9941 - val_loss: 0.1103 - val_accuracy: 0.9561\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0449 - accuracy: 0.9941 - val_loss: 0.1102 - val_accuracy: 0.9561\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0441 - accuracy: 0.9941 - val_loss: 0.1102 - val_accuracy: 0.9561\n",
      "Epoch 115/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0434 - accuracy: 0.9941 - val_loss: 0.1102 - val_accuracy: 0.9561\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0427 - accuracy: 0.9941 - val_loss: 0.1102 - val_accuracy: 0.9561\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0420 - accuracy: 0.9941 - val_loss: 0.1102 - val_accuracy: 0.9561\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0413 - accuracy: 0.9941 - val_loss: 0.1103 - val_accuracy: 0.9561\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0407 - accuracy: 0.9941 - val_loss: 0.1104 - val_accuracy: 0.9561\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0400 - accuracy: 0.9941 - val_loss: 0.1105 - val_accuracy: 0.9561\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0394 - accuracy: 0.9941 - val_loss: 0.1106 - val_accuracy: 0.9561\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0387 - accuracy: 0.9941 - val_loss: 0.1107 - val_accuracy: 0.9561\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0381 - accuracy: 0.9941 - val_loss: 0.1109 - val_accuracy: 0.9561\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0375 - accuracy: 0.9941 - val_loss: 0.1110 - val_accuracy: 0.9561\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0370 - accuracy: 0.9941 - val_loss: 0.1111 - val_accuracy: 0.9561\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0364 - accuracy: 0.9941 - val_loss: 0.1113 - val_accuracy: 0.9561\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0359 - accuracy: 0.9941 - val_loss: 0.1114 - val_accuracy: 0.9561\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0353 - accuracy: 0.9941 - val_loss: 0.1116 - val_accuracy: 0.9561\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0348 - accuracy: 0.9941 - val_loss: 0.1118 - val_accuracy: 0.9561\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0343 - accuracy: 0.9941 - val_loss: 0.1120 - val_accuracy: 0.9561\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0338 - accuracy: 0.9941 - val_loss: 0.1122 - val_accuracy: 0.9561\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0333 - accuracy: 0.9941 - val_loss: 0.1124 - val_accuracy: 0.9561\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0329 - accuracy: 0.9941 - val_loss: 0.1126 - val_accuracy: 0.9561\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0324 - accuracy: 0.9941 - val_loss: 0.1129 - val_accuracy: 0.9561\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0319 - accuracy: 0.9941 - val_loss: 0.1131 - val_accuracy: 0.9561\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0315 - accuracy: 0.9941 - val_loss: 0.1133 - val_accuracy: 0.9561\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0310 - accuracy: 0.9941 - val_loss: 0.1135 - val_accuracy: 0.9561\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0306 - accuracy: 0.9941 - val_loss: 0.1138 - val_accuracy: 0.9561\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0302 - accuracy: 0.9971 - val_loss: 0.1141 - val_accuracy: 0.9561\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0297 - accuracy: 0.9971 - val_loss: 0.1143 - val_accuracy: 0.9561\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0293 - accuracy: 0.9971 - val_loss: 0.1146 - val_accuracy: 0.9561\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0289 - accuracy: 0.9971 - val_loss: 0.1148 - val_accuracy: 0.9561\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0285 - accuracy: 0.9971 - val_loss: 0.1151 - val_accuracy: 0.9561\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0281 - accuracy: 0.9971 - val_loss: 0.1153 - val_accuracy: 0.9561\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0277 - accuracy: 0.9971 - val_loss: 0.1156 - val_accuracy: 0.9561\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0273 - accuracy: 0.9971 - val_loss: 0.1159 - val_accuracy: 0.9561\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0269 - accuracy: 0.9971 - val_loss: 0.1162 - val_accuracy: 0.9561\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0266 - accuracy: 0.9971 - val_loss: 0.1165 - val_accuracy: 0.9561\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0262 - accuracy: 0.9971 - val_loss: 0.1167 - val_accuracy: 0.9561\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0258 - accuracy: 0.9971 - val_loss: 0.1170 - val_accuracy: 0.9561\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0255 - accuracy: 0.9971 - val_loss: 0.1173 - val_accuracy: 0.9561\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0251 - accuracy: 0.9971 - val_loss: 0.1175 - val_accuracy: 0.9561\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0248 - accuracy: 0.9971 - val_loss: 0.1178 - val_accuracy: 0.9561\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0245 - accuracy: 0.9971 - val_loss: 0.1180 - val_accuracy: 0.9561\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.1183 - val_accuracy: 0.9561\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0238 - accuracy: 0.9971 - val_loss: 0.1185 - val_accuracy: 0.9561\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0235 - accuracy: 0.9971 - val_loss: 0.1188 - val_accuracy: 0.9561\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0232 - accuracy: 0.9971 - val_loss: 0.1190 - val_accuracy: 0.9561\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0229 - accuracy: 0.9971 - val_loss: 0.1193 - val_accuracy: 0.9561\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0226 - accuracy: 0.9971 - val_loss: 0.1196 - val_accuracy: 0.9561\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0223 - accuracy: 0.9971 - val_loss: 0.1198 - val_accuracy: 0.9561\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0220 - accuracy: 0.9971 - val_loss: 0.1200 - val_accuracy: 0.9561\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0217 - accuracy: 0.9971 - val_loss: 0.1202 - val_accuracy: 0.9561\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0214 - accuracy: 0.9971 - val_loss: 0.1205 - val_accuracy: 0.9561\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0211 - accuracy: 0.9971 - val_loss: 0.1207 - val_accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "# 학습한다.\n",
    "# 첫번째, 두번째 : 학습데이터\n",
    "# 세번째 : 학습 횟수\n",
    "# 네번째 : 학습을 위해 사용하는 메모리 공간(ram이나 vram)에 저장하는\n",
    "# 데이터 양.\n",
    "# validation_data : 검증용으로 사용할 데이터\n",
    "# callbacks : 조기중단, 자동저장을 설정한다.\n",
    "history = model.fit(X_train, y_train, epochs=10000, batch_size=500,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks=[callback1, callback2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b5602c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'][:-50], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'][:-50], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08975ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'][:-50], label='loss')\n",
    "plt.plot(history.history['val_loss'][:-50], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cad6714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a52d2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1ded4e3f640>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 복원한다\n",
    "best_model = load_model('06_model.h5')\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51fd4bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.33602613e-04],\n",
       "       [7.23670721e-02],\n",
       "       [5.78571148e-02],\n",
       "       [5.59280568e-04],\n",
       "       [3.53972078e-04],\n",
       "       [9.98742521e-01],\n",
       "       [9.91992712e-01],\n",
       "       [1.11257087e-03],\n",
       "       [8.51424469e-04],\n",
       "       [2.90818010e-02],\n",
       "       [9.89935994e-01],\n",
       "       [9.83434916e-01],\n",
       "       [9.88325953e-01],\n",
       "       [6.43685520e-01],\n",
       "       [9.73460734e-01],\n",
       "       [1.38591728e-04],\n",
       "       [1.39491510e-06],\n",
       "       [1.60632953e-02],\n",
       "       [1.61783106e-03],\n",
       "       [5.59753999e-02],\n",
       "       [9.82972085e-01],\n",
       "       [8.63289897e-05],\n",
       "       [9.90638196e-01],\n",
       "       [9.48022842e-01],\n",
       "       [1.53498882e-02],\n",
       "       [8.52496829e-04],\n",
       "       [9.45832551e-01],\n",
       "       [9.93780851e-01],\n",
       "       [4.53311571e-07],\n",
       "       [9.48066056e-01],\n",
       "       [2.02891199e-04],\n",
       "       [9.40102339e-01],\n",
       "       [1.05764411e-05],\n",
       "       [6.50921417e-03],\n",
       "       [3.41308216e-04],\n",
       "       [7.78359622e-02],\n",
       "       [9.92796838e-01],\n",
       "       [9.98564720e-01],\n",
       "       [7.93981424e-04],\n",
       "       [9.32485282e-01],\n",
       "       [3.35726258e-03],\n",
       "       [9.30195153e-01],\n",
       "       [6.17622959e-07],\n",
       "       [2.07511652e-02],\n",
       "       [8.79909575e-01],\n",
       "       [9.97421980e-01],\n",
       "       [1.18266374e-01],\n",
       "       [1.63140594e-05],\n",
       "       [1.95316225e-03],\n",
       "       [8.50231349e-01],\n",
       "       [2.14132480e-03],\n",
       "       [6.41311868e-04],\n",
       "       [9.55328643e-01],\n",
       "       [1.11878233e-03],\n",
       "       [6.74186322e-06],\n",
       "       [7.84519070e-04],\n",
       "       [9.99788523e-01],\n",
       "       [4.76697141e-06],\n",
       "       [7.19615910e-03],\n",
       "       [5.50522804e-01],\n",
       "       [9.82654274e-01],\n",
       "       [9.96655226e-01],\n",
       "       [2.83150817e-04],\n",
       "       [7.55824089e-01],\n",
       "       [4.20128235e-05],\n",
       "       [3.85863270e-04],\n",
       "       [1.12155685e-03],\n",
       "       [3.88487184e-04],\n",
       "       [2.13391706e-03],\n",
       "       [7.10388133e-03],\n",
       "       [9.82495840e-06],\n",
       "       [9.51669991e-01],\n",
       "       [9.83011663e-01],\n",
       "       [7.42943448e-05],\n",
       "       [9.71146762e-01],\n",
       "       [5.38206799e-03],\n",
       "       [9.70619500e-01],\n",
       "       [7.32311141e-03],\n",
       "       [9.99964058e-01],\n",
       "       [5.19671768e-04],\n",
       "       [2.55260849e-04],\n",
       "       [5.75233949e-04],\n",
       "       [9.92517233e-01],\n",
       "       [9.99967217e-01],\n",
       "       [5.54834127e-01],\n",
       "       [7.84764647e-01],\n",
       "       [9.92749512e-01],\n",
       "       [5.30492375e-03],\n",
       "       [1.99006579e-04],\n",
       "       [9.97710884e-01],\n",
       "       [4.03344817e-02],\n",
       "       [9.91923094e-01],\n",
       "       [3.80492628e-01],\n",
       "       [1.76598787e-05],\n",
       "       [9.56867239e-04],\n",
       "       [5.60499821e-03],\n",
       "       [5.46653318e-05],\n",
       "       [4.69367206e-03],\n",
       "       [1.41682839e-02],\n",
       "       [1.80745337e-06],\n",
       "       [2.52386485e-03],\n",
       "       [9.59955752e-01],\n",
       "       [9.65242326e-01],\n",
       "       [6.17106562e-05],\n",
       "       [3.91697288e-01],\n",
       "       [9.49352086e-01],\n",
       "       [1.21348174e-02],\n",
       "       [1.40205782e-04],\n",
       "       [5.38853172e-04],\n",
       "       [7.24980116e-01],\n",
       "       [1.81043462e-04],\n",
       "       [8.74988064e-02],\n",
       "       [1.66501573e-04],\n",
       "       [5.42130438e-04]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증데이터를 가지고 예측한다\n",
    "pred = best_model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43915706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과를 환산하고 평가한다\n",
    "y = (pred>= 0.5).astype('int')\n",
    "y = y.reshape(-1) # 1차원으로 만듦\n",
    "\n",
    "r1 = accuracy_score(y_test, y)\n",
    "r1 # 예측 정확도가 0.95임 테스트 데이터의 0.95의 정확도를 기준으로\n",
    "# 미래데이터 정확도랑 비교하면서 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1f8e7",
   "metadata": {},
   "source": [
    "### 예측한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55816b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.62</td>\n",
       "      <td>17.15</td>\n",
       "      <td>80.62</td>\n",
       "      <td>492.9</td>\n",
       "      <td>0.08583</td>\n",
       "      <td>0.05430</td>\n",
       "      <td>0.02966</td>\n",
       "      <td>0.02272</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.05826</td>\n",
       "      <td>...</td>\n",
       "      <td>14.340</td>\n",
       "      <td>22.15</td>\n",
       "      <td>91.62</td>\n",
       "      <td>633.5</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.18870</td>\n",
       "      <td>0.09851</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.07330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.38</td>\n",
       "      <td>30.72</td>\n",
       "      <td>86.34</td>\n",
       "      <td>557.2</td>\n",
       "      <td>0.09245</td>\n",
       "      <td>0.07426</td>\n",
       "      <td>0.02819</td>\n",
       "      <td>0.03264</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.06016</td>\n",
       "      <td>...</td>\n",
       "      <td>15.050</td>\n",
       "      <td>41.61</td>\n",
       "      <td>96.69</td>\n",
       "      <td>705.6</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.14210</td>\n",
       "      <td>0.07003</td>\n",
       "      <td>0.07763</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.63</td>\n",
       "      <td>29.29</td>\n",
       "      <td>74.87</td>\n",
       "      <td>415.1</td>\n",
       "      <td>0.09357</td>\n",
       "      <td>0.08574</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.02017</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.06166</td>\n",
       "      <td>...</td>\n",
       "      <td>13.120</td>\n",
       "      <td>38.81</td>\n",
       "      <td>86.04</td>\n",
       "      <td>527.8</td>\n",
       "      <td>0.14060</td>\n",
       "      <td>0.20310</td>\n",
       "      <td>0.29230</td>\n",
       "      <td>0.06835</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.07220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.21</td>\n",
       "      <td>25.25</td>\n",
       "      <td>84.10</td>\n",
       "      <td>537.9</td>\n",
       "      <td>0.08791</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.02772</td>\n",
       "      <td>0.02068</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.05584</td>\n",
       "      <td>...</td>\n",
       "      <td>14.350</td>\n",
       "      <td>34.23</td>\n",
       "      <td>91.29</td>\n",
       "      <td>632.9</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.06005</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.06788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.00</td>\n",
       "      <td>25.13</td>\n",
       "      <td>82.61</td>\n",
       "      <td>520.2</td>\n",
       "      <td>0.08369</td>\n",
       "      <td>0.05073</td>\n",
       "      <td>0.01206</td>\n",
       "      <td>0.01762</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>...</td>\n",
       "      <td>14.340</td>\n",
       "      <td>31.88</td>\n",
       "      <td>91.06</td>\n",
       "      <td>628.5</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.05921</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.06291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.41070</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.16280</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.34030</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.93870</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          12.62         17.15           80.62      492.9          0.08583   \n",
       "1          13.38         30.72           86.34      557.2          0.09245   \n",
       "2          11.63         29.29           74.87      415.1          0.09357   \n",
       "3          13.21         25.25           84.10      537.9          0.08791   \n",
       "4          13.00         25.13           82.61      520.2          0.08369   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "110        21.56         22.39          142.00     1479.0          0.11100   \n",
       "111        20.13         28.25          131.20     1261.0          0.09780   \n",
       "112        16.60         28.08          108.30      858.1          0.08455   \n",
       "113        20.60         29.33          140.10     1265.0          0.11780   \n",
       "114         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.05430         0.02966              0.02272         0.1799   \n",
       "1             0.07426         0.02819              0.03264         0.1375   \n",
       "2             0.08574         0.07160              0.02017         0.1799   \n",
       "3             0.05205         0.02772              0.02068         0.1619   \n",
       "4             0.05073         0.01206              0.01762         0.1667   \n",
       "..                ...             ...                  ...            ...   \n",
       "110           0.11590         0.24390              0.13890         0.1726   \n",
       "111           0.10340         0.14400              0.09791         0.1752   \n",
       "112           0.10230         0.09251              0.05302         0.1590   \n",
       "113           0.27700         0.35140              0.15200         0.2397   \n",
       "114           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.05826  ...        14.340          22.15   \n",
       "1                   0.06016  ...        15.050          41.61   \n",
       "2                   0.06166  ...        13.120          38.81   \n",
       "3                   0.05584  ...        14.350          34.23   \n",
       "4                   0.05449  ...        14.340          31.88   \n",
       "..                      ...  ...           ...            ...   \n",
       "110                 0.05623  ...        25.450          26.40   \n",
       "111                 0.05533  ...        23.690          38.25   \n",
       "112                 0.05648  ...        18.980          34.12   \n",
       "113                 0.07016  ...        25.740          39.42   \n",
       "114                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0              91.62       633.5           0.12250            0.15170   \n",
       "1              96.69       705.6           0.11720            0.14210   \n",
       "2              86.04       527.8           0.14060            0.20310   \n",
       "3              91.29       632.9           0.12890            0.10630   \n",
       "4              91.06       628.5           0.12180            0.10930   \n",
       "..               ...         ...               ...                ...   \n",
       "110           166.10      2027.0           0.14100            0.21130   \n",
       "111           155.00      1731.0           0.11660            0.19220   \n",
       "112           126.70      1124.0           0.11390            0.30940   \n",
       "113           184.60      1821.0           0.16500            0.86810   \n",
       "114            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0            0.18870               0.09851          0.3270   \n",
       "1            0.07003               0.07763          0.2196   \n",
       "2            0.29230               0.06835          0.2884   \n",
       "3            0.13900               0.06005          0.2444   \n",
       "4            0.04462               0.05921          0.2306   \n",
       "..               ...                   ...             ...   \n",
       "110          0.41070               0.22160          0.2060   \n",
       "111          0.32150               0.16280          0.2572   \n",
       "112          0.34030               0.14180          0.2218   \n",
       "113          0.93870               0.26500          0.4087   \n",
       "114          0.00000               0.00000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.07330  \n",
       "1                    0.07675  \n",
       "2                    0.07220  \n",
       "3                    0.06788  \n",
       "4                    0.06291  \n",
       "..                       ...  \n",
       "110                  0.07115  \n",
       "111                  0.06637  \n",
       "112                  0.07820  \n",
       "113                  0.12400  \n",
       "114                  0.07039  \n",
       "\n",
       "[115 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러온다\n",
    "df2 = pd.read_csv('data/breast_cancer_new.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e579b290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46250369, -0.45164581, -0.50218195, ..., -0.28043066,\n",
       "         0.5116929 , -0.5831113 ],\n",
       "       [-0.24537993,  2.87283471, -0.26498762, ..., -0.59279929,\n",
       "        -1.15425761, -0.39577673],\n",
       "       [-0.74533596,  2.52250257, -0.7406203 , ..., -0.7316298 ,\n",
       "        -0.08705654, -0.64284116],\n",
       "       ...,\n",
       "       [ 0.67453917,  2.22606768,  0.64563954, ...,  0.3671957 ,\n",
       "        -1.12013199, -0.31704191],\n",
       "       [ 1.81729582,  2.53230207,  1.96430728, ...,  2.21029035,\n",
       "         1.77899418,  2.16989242],\n",
       "       [-1.85095302,  1.3588119 , -1.85817047, ..., -1.75415837,\n",
       "        -0.10722167, -0.74112394]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표준화\n",
    "X = scaler1.transform(df2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "879329b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1ded65abd30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델을 복원한다.\n",
    "best_model = load_model('06_model.h5')\n",
    "best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c27eb0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.89471155e-04],\n",
       "       [5.46551168e-01],\n",
       "       [2.29010835e-01],\n",
       "       [1.39564663e-01],\n",
       "       [7.73034766e-02],\n",
       "       [9.46181826e-04],\n",
       "       [9.75686014e-01],\n",
       "       [9.99999285e-01],\n",
       "       [2.02318281e-02],\n",
       "       [4.04317281e-04],\n",
       "       [9.22040734e-03],\n",
       "       [1.57139581e-02],\n",
       "       [1.19507290e-01],\n",
       "       [1.45548722e-04],\n",
       "       [9.81598973e-01],\n",
       "       [2.50918090e-01],\n",
       "       [2.82552704e-04],\n",
       "       [5.16435206e-01],\n",
       "       [9.03790444e-03],\n",
       "       [2.43248474e-02],\n",
       "       [1.77029346e-04],\n",
       "       [5.87162329e-04],\n",
       "       [1.01700671e-01],\n",
       "       [2.12892628e-04],\n",
       "       [3.95622163e-04],\n",
       "       [9.68556583e-01],\n",
       "       [4.42672195e-03],\n",
       "       [4.13426310e-02],\n",
       "       [9.15294141e-03],\n",
       "       [7.87824951e-03],\n",
       "       [3.54208320e-01],\n",
       "       [1.92229524e-02],\n",
       "       [6.77076653e-02],\n",
       "       [9.95713592e-01],\n",
       "       [5.60872769e-03],\n",
       "       [3.20740998e-01],\n",
       "       [2.77345181e-02],\n",
       "       [5.28972149e-01],\n",
       "       [9.44073915e-01],\n",
       "       [1.25170145e-05],\n",
       "       [5.95280388e-03],\n",
       "       [2.62040466e-01],\n",
       "       [2.92936027e-01],\n",
       "       [2.87551247e-03],\n",
       "       [9.66180861e-01],\n",
       "       [9.96132612e-01],\n",
       "       [1.90078378e-01],\n",
       "       [9.66527343e-01],\n",
       "       [1.76408526e-03],\n",
       "       [9.98996735e-01],\n",
       "       [4.60920017e-03],\n",
       "       [1.03420904e-03],\n",
       "       [2.36139097e-03],\n",
       "       [8.16704240e-04],\n",
       "       [7.71590769e-02],\n",
       "       [9.86059368e-01],\n",
       "       [2.28644039e-05],\n",
       "       [8.80321895e-04],\n",
       "       [9.42368507e-01],\n",
       "       [3.12434789e-02],\n",
       "       [7.59643555e-01],\n",
       "       [6.28857699e-04],\n",
       "       [9.78619754e-01],\n",
       "       [9.87762451e-01],\n",
       "       [3.54865223e-01],\n",
       "       [1.05422139e-02],\n",
       "       [5.33088205e-05],\n",
       "       [9.99590397e-01],\n",
       "       [8.00394555e-05],\n",
       "       [1.23404086e-01],\n",
       "       [7.12574343e-04],\n",
       "       [4.41168995e-05],\n",
       "       [7.00496435e-01],\n",
       "       [1.86924561e-04],\n",
       "       [1.65609911e-01],\n",
       "       [7.63902499e-04],\n",
       "       [1.25862926e-01],\n",
       "       [6.86604381e-02],\n",
       "       [5.12378477e-03],\n",
       "       [9.77604806e-01],\n",
       "       [5.28336852e-04],\n",
       "       [9.94665384e-01],\n",
       "       [8.15319479e-01],\n",
       "       [4.14499402e-01],\n",
       "       [1.37586787e-04],\n",
       "       [7.65422956e-05],\n",
       "       [1.03577979e-04],\n",
       "       [4.40554827e-01],\n",
       "       [2.47176781e-01],\n",
       "       [1.02209650e-01],\n",
       "       [1.33096715e-02],\n",
       "       [5.44142723e-02],\n",
       "       [2.72530506e-05],\n",
       "       [5.70678494e-05],\n",
       "       [1.15737770e-04],\n",
       "       [3.02608535e-02],\n",
       "       [4.03839076e-05],\n",
       "       [2.52129976e-04],\n",
       "       [1.11746021e-01],\n",
       "       [2.28946246e-05],\n",
       "       [4.08240519e-02],\n",
       "       [8.61988962e-03],\n",
       "       [4.86266763e-05],\n",
       "       [2.98209465e-03],\n",
       "       [3.03354766e-03],\n",
       "       [2.22191270e-02],\n",
       "       [3.16425860e-01],\n",
       "       [2.19055149e-03],\n",
       "       [9.98015881e-01],\n",
       "       [9.99229729e-01],\n",
       "       [9.97502506e-01],\n",
       "       [9.83526587e-01],\n",
       "       [8.84760499e-01],\n",
       "       [9.99930561e-01],\n",
       "       [2.35426942e-05]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측한다.\n",
    "pred = best_model.predict(X)\n",
    "pred\n",
    "# 반환값이 2차원 행렬임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "004cd58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값 환산\n",
    "# 0.5 이상은 1, 미만은 0으로 환산한다.\n",
    "y = (pred >= 0.5).astype('int')\n",
    "y = y.reshape(-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "130832a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열로 변환\n",
    "result = encoder1.inverse_transform(y)\n",
    "# 저장한다\n",
    "df2['target'] = result\n",
    "df2.to_csv('data/breast_cancer_dl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8aa4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
